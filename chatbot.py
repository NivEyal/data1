"""
×¦'××˜×‘×•×˜ ×¤×™× × ×¡×™
"""
import streamlit as st
from openai import OpenAI
from config import OPENAI_MODEL


class FinancialChatbot:
    """×¦'××˜×‘×•×˜ ×œ×™×™×¢×•×¥ ×¤×™× × ×¡×™"""
    
    def __init__(self):
        self.client = self._initialize_openai_client()
        self.model = OPENAI_MODEL
    
    def _initialize_openai_client(self):
        """××ª×—×•×œ ×œ×§×•×— OpenAI"""
        try:
            return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        except Exception as e:
            st.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××¤×ª×— OpenAI: {e}")
            return None
    
    def is_available(self):
        """×‘×“×™×§×” ×× ×”×¦'××˜×‘×•×˜ ×–××™×Ÿ"""
        return self.client is not None
    
    def create_financial_context(self, analysis_data):
        """×™×¦×™×¨×ª ×”×§×©×¨ ×¤×™× × ×¡×™ ×œ××©×ª××©"""
        if not analysis_data.get('analysis_done', False):
            return ""
        
        context = f"""
--- ×¡×™×›×•× ×¤×™× × ×¡×™ ×©×œ ×”××©×ª××© ---
×¡×š ×—×•×‘×•×ª: {analysis_data.get('total_debts', 0):,.0f} â‚ª
×”×›× ×¡×” ×©× ×ª×™×ª: {analysis_data.get('annual_income', 0):,.0f} â‚ª
×™×—×¡ ×—×•×‘ ×œ×”×›× ×¡×”: {analysis_data.get('debt_to_income_ratio', 0):.2%}
"""
        
        if analysis_data.get('classification'):
            context += f"×¡×™×•×•×’ ×”××¦×‘: {analysis_data['classification']}\n"
        
        if analysis_data.get('collection_proceedings') is not None:
            context += f"×”×œ×™×›×™ ×’×‘×™×™×”: {'×›×Ÿ' if analysis_data['collection_proceedings'] else '×œ×'}\n"
        
        if analysis_data.get('can_raise_funds') is not None:
            context += f"×™×›×•×œ×ª ×œ×’×™×™×¡ 50% ××”×—×•×‘: {'×›×Ÿ' if analysis_data['can_raise_funds'] else '×œ×'}\n"
        
        context += "--- ×¡×•×£ ×¡×™×›×•× ×¤×™× × ×¡×™ ---\n"
        return context
    
    def get_response(self, user_message, financial_context=""):
        """×§×‘×œ×ª ×ª×©×•×‘×” ××”×¦'××˜×‘×•×˜"""
        if not self.client:
            return "××¦×˜×¢×¨, ×©×™×¨×•×ª ×”×¦'××˜ ××™× ×• ×–××™×Ÿ ×›×¨×’×¢."
        
        system_message = f"""
××ª×” ××•××—×” ×œ×›×œ×›×œ×ª ×”××©×¤×—×” ×‘×™×©×¨××œ. 
×”××˜×¨×” ×©×œ×š ×”×™× ×œ×¡×¤×§ ×™×™×¢×•×¥ ×¤×™× × ×¡×™ ×‘×¨×•×¨, ××¢×©×™ ×•×§×œ ×œ×”×‘× ×”.
×¢× ×” ×‘×¢×‘×¨×™×ª ×‘×¦×•×¨×” ×—××” ×•××§×¦×•×¢×™×ª.
{financial_context}
"""
        
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                stream=True,
                temperature=0.7
            )
            return response
        except Exception as e:
            return f"××¦×˜×¢×¨, ×”×ª×¨×—×©×” ×©×’×™××”: {e}"
    
    def display_chat_interface(self, analysis_data):
        """×”×¦×’×ª ×××©×§ ×”×¦'××˜"""
        st.header("ğŸ’¬ ×¦'××˜ ×¢× ××•××—×” ×›×œ×›×œ×ª ×”××©×¤×—×”")
        
        if not self.is_available():
            st.warning("×©×™×¨×•×ª ×”×¦'××˜ ××™× ×• ×–××™×Ÿ ×¢×§×‘ ×‘×¢×™×” ×‘×”×’×“×¨×•×ª.")
            return
        
        # ×”×¦×’×ª ×”×•×“×¢×•×ª ×§×™×™××•×ª
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ×§×œ×˜ ×—×“×© ××”××©×ª××©
        if prompt := st.chat_input("×©××œ ××•×ª×™ ×›×œ ×©××œ×” ×¢×œ ××¦×‘×š ×”×¤×™× × ×¡×™..."):
            # ×”×•×¡×¤×ª ×”×•×“×¢×ª ×”××©×ª××©
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ×™×¦×™×¨×ª ×ª×©×•×‘×”
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                
                financial_context = self.create_financial_context(analysis_data)
                response_stream = self.get_response(prompt, financial_context)
                
                if isinstance(response_stream, str):
                    # ×©×’×™××”
                    full_response = response_stream
                    message_placeholder.markdown(full_response)
                else:
                    # ×ª×©×•×‘×” ××•×–×¨××ª
                    for chunk in response_stream:
                        if chunk.choices[0].delta.content is not None:
                            full_response += chunk.choices[0].delta.content
                            message_placeholder.markdown(full_response + "â–Œ")
                    message_placeholder.markdown(full_response)
            
            # ×©××™×¨×ª ×”×ª×©×•×‘×”
            st.session_state.messages.append({"role": "assistant", "content": full_response})